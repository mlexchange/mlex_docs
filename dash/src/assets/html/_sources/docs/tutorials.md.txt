# Tutorials
## Applications
### Image segmentation
This application performs image segmentation in TIF images (supports a single image or volume).

<img src="./figures/seg_demo.png" width="600">

**Currently available ML models**  
* Random Forest (supervised learning) [source]  
* pyMSDtorch (supervised learning) [documentation](http://pymsdtorch.readthedocs.io)  
* K-Means (unsupervised learning) [Howard + Nick - ANL]

**Supervised vs. unsupervised learning**  
A supervised learning algorithm utilizes labeled datasets to train their models, while an unsupervised learning approach does not need this information to perform training. 

### How to run a segmentation model in the MLExchange platform?  
**Choose a dataset** at the top left section of the app.

**Choose an ML model:** When choosing a supervised learning algorithm, you need to provide annotations (labels). 
These annotations represent the ground truth information that the algorithm utilizes to train the model.
When choosing an unsupervised algorithm, you do not need to provide annotations. 
The segmentation app allows 2 different training options for this type of algorithms:
You can mark some few images to be used for training.
If no marks are provided, the algorithm utilizes the entire stack of images for training.
It is important to clarify that these marks do not correspond to annotations/labels/ground truth.
Select the values of the model parameters and click TRAIN
You can check the status of the training process in the list of jobs at the bottom left section of the app. 
To check the logs of the process, select the corresponding job in the list and the logs will appear at the bottom right section of the app.
Once the model is trained (marked as completed), you can proceed to test this model. To do this, select the dataset you want to test, and click TEST.
You can check the status of the testing process in the list of jobs at the bottom left section of the app.
Once the image stack is completely segmented, you can check the Show Segmentation box on the right to visualize the testing results in the graph.

## Contributing your workflow to MLExchange
### Model preparation
The first step to submit a new model in MLExchange is to dockerize your script. To simplify this process, you can use the following templates (Python):
****include templates****

Use `src/model_name.py` to place your algorithm. You can rename this file according to your function/command, e.g. train.py. While modifying this template, please make sure to identify 3 main sections of your code:
Input directory(ies)
Output directory(ies)
Parameters [Optional]
The template indicates how to declare this information and the order in which they should be declared. If you have more than one input directory, you should list these directories consecutively. The same applies for the output directories.
Note: If you have more than one function/command, create another script with the same template, and save it with a different name, e.g. test.py
Use `src/model_validation.py` to define the parameter classes (if you have any) that are used in your source files. For validation purposes, MLExchange uses [Pydantic](https://pydantic-docs.helpmanual.io).
List the Python packages you utilized in your source code with their corresponding versions in docker/requirements.txt.
Insert the maintainer’s name in line 2 in docker/Dockerfile.
Insert your project name in line 4 in Makefile.
[Optional] You can add example commands in Makefile.
Once all changes have been completed, open a terminal window and type “build_docker”.
You have successfully dockerized your model!

For further assistance, please contact [tanchavez@lbl.gov](mailto:tanchavez@lbl.gov) or [zzhao2@lbl.gov](mailto:zzhao2@lbl.gov).

### Model registration
You can register a new model at [MLExchagne Model Registry](https://mlsandbox.als.lbl.gov/model-registry)

**Register your model by**  
Creating a json file with the description of your model (fill out the online form to generate your model document), and upload your model document to the model registry.


**Parameter definition**  
The parameter class you previously defined for your source files corresponds to the GUI’s components that MLExchange automatically generates within its applications. You can define these parameters in the json file, or you can use the model registry form to add each GUI component. 

Currently, the model registry supports 8 different types of components:
* 3 types of input box: int, float, and string  
* Dropdown  
* Slider  
* RadioItem  
* BooleanSwitch  
* Graph
